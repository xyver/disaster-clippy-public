# Web framework
fastapi>=0.104.0
uvicorn>=0.24.0
jinja2>=3.1.0

# LLM and embeddings
langchain>=0.1.0
langchain-openai>=0.0.5  # For embeddings (required) + optional chat
openai>=1.0.0
langchain-anthropic>=0.1.0  # Optional: for Claude chat (install if using)

# Vector database
chromadb>=0.4.0  # Local development
pinecone>=8.0.0  # Optional: cloud vector DB (install if using)

# Web scraping
requests>=2.31.0
beautifulsoup4>=4.12.0
lxml>=4.9.0

# HTTP client (async support)
httpx>=0.25.0

# Utilities
python-dotenv>=1.0.0
pydantic>=2.0.0

# Data processing / visualization
numpy>=1.24.0
scikit-learn>=1.3.0  # For PCA in knowledge map visualization

# Rate limiting for scraping
ratelimit>=2.2.1

# Rate limiting for API endpoints
slowapi>=0.1.9

# Cloud storage (R2/S3)
boto3>=1.34.0

# Local embeddings (offline mode)
sentence-transformers>=2.2.0

# Translation (language packs)
transformers>=4.30.0
sentencepiece>=0.1.99
sacremoses>=0.0.53

# ZIM file reading (offline articles)
zimply-core>=1.0.0

# Local LLM (llama.cpp runtime) - OPTIONAL, install manually for local inference:
# pip install llama-cpp-python
# Note: Excluded from cloud deployments as it requires C++ compilation
